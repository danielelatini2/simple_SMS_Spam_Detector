{
 "cells": [
  {
   "metadata": {},
   "cell_type": "raw",
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# SMS Spam Detection - Exploratory Data Analysis\\n\",\n",
    "    \"\\n\",\n",
    "    \"This notebook provides exploratory data analysis and experimentation for the SMS spam detection system.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Import necessary libraries\\n\",\n",
    "    \"import sys\\n\",\n",
    "    \"import pandas as pd\\n\",\n",
    "    \"import numpy as np\\n\",\n",
    "    \"import matplotlib.pyplot as plt\\n\",\n",
    "    \"import seaborn as sns\\n\",\n",
    "    \"from pathlib import Path\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Add src to path\\n\",\n",
    "    \"sys.path.append(str(Path.cwd().parent / 'src'))\\n\",\n",
    "    \"\\n\",\n",
    "    \"from sms_spam_detector import DataLoader, TextPreprocessor, SpamClassifier, ModelEvaluator\\n\",\n",
    "    \"\\n\",\n",
    "    \"%matplotlib inline\\n\",\n",
    "    \"plt.style.use('seaborn-v0_8')\\n\",\n",
    "    \"sns.set_palette(\\\"husl\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 1. Data Loading and Overview\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Load the data\\n\",\n",
    "    \"data_loader = DataLoader()\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Download dataset if needed\\n\",\n",
    "    \"import os\\n\",\n",
    "    \"if not os.path.exists(\\\"../data/raw/sms_spam_collection/SMSSpamCollection\\\"):\\n\",\n",
    "    \"    print(\\\"Downloading dataset...\\\")\\n\",\n",
    "    \"    data_loader.download_dataset()\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Load dataset\\n\",\n",
    "    \"df = data_loader.load_dataset()\\n\",\n",
    "    \"print(f\\\"Dataset shape: {df.shape}\\\")\\n\",\n",
    "    \"print(f\\\"Columns: {df.columns.tolist()}\\\")\\n\",\n",
    "    \"df.head()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Dataset information\\n\",\n",
    "    \"dataset_info = data_loader.get_dataset_info(df)\\n\",\n",
    "    \"print(\\\"Dataset Information:\\\")\\n\",\n",
    "    \"for key, value in dataset_info.items():\\n\",\n",
    "    \"    print(f\\\"{key}: {value}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 2. Data Distribution Analysis\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Label distribution\\n\",\n",
    "    \"plt.figure(figsize=(10, 6))\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Pie chart\\n\",\n",
    "    \"plt.subplot(1, 2, 1)\\n\",\n",
    "    \"df['label'].value_counts().plot(kind='pie', autopct='%1.1f%%', startangle=90)\\n\",\n",
    "    \"plt.title('Distribution of Spam vs Ham Messages')\\n\",\n",
    "    \"plt.ylabel('')\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Bar chart\\n\",\n",
    "    \"plt.subplot(1, 2, 2)\\n\",\n",
    "    \"df['label'].value_counts().plot(kind='bar', color=['skyblue', 'lightcoral'])\\n\",\n",
    "    \"plt.title('Count of Spam vs Ham Messages')\\n\",\n",
    "    \"plt.xlabel('Label')\\n\",\n",
    "    \"plt.ylabel('Count')\\n\",\n",
    "    \"plt.xticks(rotation=0)\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.tight_layout()\\n\",\n",
    "    \"plt.show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Message length analysis\\n\",\n",
    "    \"df['message_length'] = df['message'].str.len()\\n\",\n",
    "    \"df['word_count'] = df['message'].str.split().str.len()\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.figure(figsize=(15, 5))\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Message length distribution\\n\",\n",
    "    \"plt.subplot(1, 3, 1)\\n\",\n",
    "    \"df.groupby('label')['message_length'].hist(alpha=0.7, bins=30)\\n\",\n",
    "    \"plt.title('Message Length Distribution')\\n\",\n",
    "    \"plt.xlabel('Message Length (characters)')\\n\",\n",
    "    \"plt.ylabel('Frequency')\\n\",\n",
    "    \"plt.legend(['Ham', 'Spam'])\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Word count distribution\\n\",\n",
    "    \"plt.subplot(1, 3, 2)\\n\",\n",
    "    \"df.groupby('label')['word_count'].hist(alpha=0.7, bins=30)\\n\",\n",
    "    \"plt.title('Word Count Distribution')\\n\",\n",
    "    \"plt.xlabel('Word Count')\\n\",\n",
    "    \"plt.ylabel('Frequency')\\n\",\n",
    "    \"plt.legend(['Ham', 'Spam'])\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Box plot comparison\\n\",\n",
    "    \"plt.subplot(1, 3, 3)\\n\",\n",
    "    \"sns.boxplot(data=df, x='label', y='message_length')\\n\",\n",
    "    \"plt.title('Message Length by Label')\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.tight_layout()\\n\",\n",
    "    \"plt.show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 3. Text Preprocessing Analysis\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Initialize preprocessor\\n\",\n",
    "    \"preprocessor = TextPreprocessor()\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Sample messages for preprocessing demonstration\\n\",\n",
    "    \"sample_messages = df['message'].head(5)\\n\",\n",
    "    \"print(\\\"Original Messages:\\\")\\n\",\n",
    "    \"for i, msg in enumerate(sample_messages, 1):\\n\",\n",
    "    \"    print(f\\\"{i}. {msg}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"\\\\nProcessed Messages:\\\")\\n\",\n",
    "    \"processed_messages = preprocessor.preprocess_text(sample_messages, verbose=True)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 4. Model Training and Evaluation\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Clean dataset\\n\",\n",
    "    \"df_clean = data_loader.clean_dataset(df)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Preprocess all messages\\n\",\n",
    "    \"print(\\\"Preprocessing all messages...\\\")\\n\",\n",
    "    \"df_clean['processed_message'] = preprocessor.preprocess_text(df_clean['message'])\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"Cleaned dataset shape: {df_clean.shape}\\\")\\n\",\n",
    "    \"df_clean.head()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Train model with grid search\\n\",\n",
    "    \"classifier = SpamClassifier()\\n\",\n",
    "    \"print(\\\"Training model with grid search...\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"training_results = classifier.train_with_grid_search(\\n\",\n",
    "    \"    df_clean['processed_message'],\\n\",\n",
    "    \"    df_clean['label']\\n\",\n",
    "    \")\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"Best parameters: {training_results['best_params']}\\\")\\n\",\n",
    "    \"print(f\\\"Best cross-validation score: {training_results['best_score']:.4f}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Evaluate model\\n\",\n",
    "    \"evaluator = ModelEvaluator(preprocessor)\\n\",\n",
    "    \"\\n\",\n",
    "    \"evaluation_results = classifier.evaluate_on_split(\\n\",\n",
    "    \"    df_clean['processed_message'],\\n\",\n",
    "    \"    df_clean['label']\\n\",\n",
    "    \")\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"F1-Score: {evaluation_results['f1_score']:.4f}\\\")\\n\",\n",
    "    \"print(\\\"\\\\nConfusion Matrix:\\\")\\n\",\n",
    "    \"print(evaluation_results['confusion_matrix'])\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Plot confusion matrix\\n\",\n",
    "    \"evaluator.plot_confusion_matrix(evaluation_results['confusion_matrix'])\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 5. Feature Analysis\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Get feature names from the trained model\\n\",\n",
    "    \"feature_names = classifier.get_feature_names()\\n\",\n",
    "    \"print(f\\\"Total features: {len(feature_names)}\\\")\\n\",\n",
    "    \"print(f\\\"First 20 features: {feature_names[:20]}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Get feature importances (coefficients for Naive Bayes)\\n\",\n",
    "    \"nb_classifier = classifier.best_model.named_steps['classifier']\\n\",\n",
    "    \"feature_log_prob = nb_classifier.feature_log_prob_\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Calculate feature importance as difference between spam and ham probabilities\\n\",\n",
    "    \"feature_importance = feature_log_prob[1] - feature_log_prob[0]\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Get top spam indicators\\n\",\n",
    "    \"top_spam_indices = np.argsort(feature_importance)[-20:]\\n\",\n",
    "    \"top_spam_features = [(feature_names[i], feature_importance[i]) for i in top_spam_indices]\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"Top 20 Spam Indicators:\\\")\\n\",\n",
    "    \"for feature, importance in reversed(top_spam_features):\\n\",\n",
    "    \"    print(f\\\"{feature}: {importance:.4f}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 6. Sample Predictions\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Test on sample messages\\n\",\n",
    "    \"sample_test_messages = [\\n\",\n",
    "    \"    \\\"Congratulations! You've won a $1000 Walmart gift card. Go to http://bit.ly/1234 to claim now.\\\",\\n\",\n",
    "    \"    \\\"Hey, are we still meeting up for lunch today?\\\",\\n\",\n",
    "    \"    \\\"Urgent! Your account has been compromised. Verify your details here: www.fakebank.com/verify\\\",\\n\",\n",
    "    \"    \\\"Reminder: Your appointment is scheduled for tomorrow at 10am.\\\",\\n\",\n",
    "    \"    \\\"FREE entry in a weekly competition to win an iPad. Just text WIN to 80085 now!\\\",\\n\",\n",
    "    \"]\\n\",\n",
    "    \"\\n\",\n",
    "    \"test_results = evaluator.test_sample_messages(classifier, sample_test_messages)\\n\",\n",
    "    \"evaluator.print_test_results(test_results)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 7. Model Performance Visualization\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Plot ROC curve if probabilities are available\\n\",\n",
    "    \"if 'probabilities' in evaluation_results:\\n\",\n",
    "    \"    y_true = classifier.prepare_labels(df_clean['label'])\\n\",\n",
    "    \"    y_pred_proba = classifier.predict_proba(df_clean['processed_message'])\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    evaluator.plot_roc_curve(y_true, y_pred_proba)\\n\",\n",
    "    \"else:\\n\",\n",
    "    \"    print(\\\"ROC curve data not available\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 8. Save Results and Model\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Save the trained model\\n\",\n",
    "    \"import os\\n\",\n",
    "    \"os.makedirs('../models', exist_ok=True)\\n\",\n",
    "    \"classifier.save_model('../models/spam_classifier_notebook.joblib')\\n\",\n",
    "    \"print(\\\"Model saved successfully!\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Save processed data\\n\",\n",
    "    \"os.makedirs('../data/processed', exist_ok=True)\\n\",\n",
    "    \"df_clean.to_csv('../data/processed/sms_spam_processed.csv', index=False)\\n\",\n",
    "    \"print(\\\"Processed data saved successfully!\\\")\"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"codemirror_mode\": {\n",
    "    \"name\": \"ipython\",\n",
    "    \"version\": 3\n",
    "   },\n",
    "   \"file_extension\": \".py\",\n",
    "   \"mimetype\": \"text/x-python\",\n",
    "   \"name\": \"python\",\n",
    "   \"nbconvert_exporter\": \"python\",\n",
    "   \"pygments_lexer\": \"ipython3\",\n",
    "   \"version\": \"3.8.10\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 4\n",
    "}\n",
    "\n"
   ],
   "id": "57ff85bd538b87f1"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
